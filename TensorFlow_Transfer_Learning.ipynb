{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjwtLEIRgvmvb1Hn/QUQBb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waleedGeorgy/deep-learning/blob/main/TensorFlow_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction & Data Preparation"
      ],
      "metadata": {
        "id": "vp0ijBWYe0SY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transfer Learning** is the process of using a pre-trained, well-performing model, on our custom, related problem. For example, using a model that was trained on millions of various images and adjust it to classify various kinds of foods.\n",
        "\n",
        "Transfer learning is a very important, efficient, and popular concept in machine learning because it can train deep neural networks faster with comparatively little data, and usually results in better models.\n",
        "\n",
        "For example, one of the best CV models, **EfficientNet**, can be repurposed to work with the problem of classifying types of food we're familiar with. We've already seen that a manually built TinyVGG does not perform very well when working with 10 types of food, so, our next course of action is to use a pretrained **EfficientNet** model to resolve our problem.\n",
        "\n",
        "There are **two** main types of transfer learning:\n",
        "\n",
        "\n",
        "1.   **Feature Extraction** - in feature extraction we use the representations (weights) learned by a previous network to extract meaningful features from new data. In feature extraction, we simply modify the output layer to match the problem we're working with, while freezing all the other layers, this means that there is no need to retrain the entire model, but rather only the modified output layer.\n",
        "2.   **Fine-Tuning** - in fine-tuning we unfreeze a few of the layers of a pretrained model and only train both the newly-added unfrozen layers and the modified output layers of said model. This allows us to \"fine-tune\" the higher-order feature representations in the base model in order to make them more relevant for the specific task.\n",
        "\n"
      ],
      "metadata": {
        "id": "_tMl36xXZhbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For that data, we'll be using a subset of the Food101 dataset, that contains only 10 types of food and 10% of the data.\n",
        "\n",
        "We're starting with a tiny subset, because in deep learning it is always a good idea to start small, check if the model works well for this tiny subset, and then add more as needed. Also working with a small subset will highlight the power of transfer learning of being able to work with a little amount of data."
      ],
      "metadata": {
        "id": "74etGLs1fHYr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM8eoOvUT_SD",
        "outputId": "4c94f482-c8eb-4bc7-90d3-72a18cea28b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-28 10:59:29--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.107.207, 74.125.196.207, 74.125.134.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.107.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip.1’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   189MB/s    in 0.9s    \n",
            "\n",
            "2024-06-28 10:59:30 (189 MB/s) - ‘10_food_classes_10_percent.zip.1’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Downloading and unzipping the data\n",
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "with zipfile.ZipFile('10_food_classes_10_percent.zip', 'r') as zipref:\n",
        "  zipref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Walking through the data directories\n",
        "import os\n",
        "\n",
        "for dirpath, dirname, filename in os.walk('10_food_classes_10_percent'):\n",
        "  print(f\"There are {len(dirname)} directories and {len(filename)} files in {dirpath}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOY4P3kff4r6",
        "outputId": "3ab02983-17d4-4764-a71c-c9c8fe72c1c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 files in 10_food_classes_10_percent.\n",
            "There are 10 directories and 0 files in 10_food_classes_10_percent/train.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/ice_cream.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/steak.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/ramen.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/sushi.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/grilled_salmon.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/fried_rice.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/hamburger.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/chicken_curry.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/chicken_wings.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/pizza.\n",
            "There are 10 directories and 0 files in 10_food_classes_10_percent/test.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/ice_cream.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/steak.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/ramen.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/sushi.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/grilled_salmon.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/fried_rice.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/hamburger.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/chicken_curry.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/chicken_wings.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/pizza.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turning our data into dataset\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = (224,224)\n",
        "\n",
        "train_dir = '10_food_classes_10_percent/train/'\n",
        "test_dir = '10_food_classes_10_percent/test/'\n",
        "\n",
        "train_data = image_dataset_from_directory(directory = train_dir,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          image_size = IMAGE_SIZE,\n",
        "                                          labels = 'inferred',\n",
        "                                          label_mode = 'categorical',\n",
        "                                          shuffle = True,\n",
        "                                          seed = 42)\n",
        "\n",
        "test_data = image_dataset_from_directory(directory = test_dir,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          image_size = IMAGE_SIZE,\n",
        "                                          labels = 'inferred',\n",
        "                                          label_mode = 'categorical',\n",
        "                                          shuffle = False,\n",
        "                                          seed = 42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnm2jWePgtRT",
        "outputId": "1f52fbc6-4afd-4c0b-82b1-4aec697d66c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the class names\n",
        "class_names = train_data.class_names\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nbibJR9heRw",
        "outputId": "31429c97-857c-425c-e485-db5ffe5a8280"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P6wwEm15hsP_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}