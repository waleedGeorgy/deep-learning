{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1l5RGmjaSVjh7tE6YCxIN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waleedGeorgy/deep-learning/blob/main/TensorFlow_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction & Data Preparation"
      ],
      "metadata": {
        "id": "vp0ijBWYe0SY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transfer Learning** is the process of using a pre-trained, well-performing model, on our custom, related problem. For example, using a model that was trained on millions of various images and adjust it to classify various kinds of foods.\n",
        "\n",
        "Transfer learning is a very important, efficient, and popular concept in machine learning because it can train deep neural networks faster with comparatively little data, and usually results in better models.\n",
        "\n",
        "For example, one of the best CV models, **EfficientNet**, can be repurposed to work with the problem of classifying types of food we're familiar with. We've already seen that a manually built TinyVGG does not perform very well when working with 10 types of food, so, our next course of action is to use a pretrained **EfficientNet** model to resolve our problem.\n",
        "\n",
        "There are **two** main types of transfer learning:\n",
        "\n",
        "\n",
        "1.   **Feature Extraction** - in feature extraction we use the representations (weights) learned by a previous network to extract meaningful features from new data. In feature extraction, we simply modify the output layer to match the problem we're working with, while freezing all the other layers, this means that there is no need to retrain the entire model, but rather only the modified output layer.\n",
        "2.   **Fine-Tuning** - in fine-tuning we unfreeze a few of the layers of a pretrained model and only train both the newly-added unfrozen layers and the modified output layers of said model. This allows us to \"fine-tune\" the higher-order feature representations in the base model in order to make them more relevant for the specific task.\n",
        "\n"
      ],
      "metadata": {
        "id": "_tMl36xXZhbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For that data, we'll be using a subset of the Food101 dataset, that contains only 10 types of food and 10% of the data.\n",
        "\n",
        "We're starting with a tiny subset, because in deep learning it is always a good idea to start small, check if the model works well for this tiny subset, and then add more as needed. Also working with a small subset will highlight the power of transfer learning of being able to work with a little amount of data."
      ],
      "metadata": {
        "id": "74etGLs1fHYr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM8eoOvUT_SD",
        "outputId": "7a171cd3-b50a-498c-ea32-830195863b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-28 18:08:31--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.118.207, 74.125.200.207, 74.125.130.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.118.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  20.9MB/s    in 8.9s    \n",
            "\n",
            "2024-06-28 18:08:41 (18.0 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Downloading and unzipping the data\n",
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "with zipfile.ZipFile('10_food_classes_10_percent.zip', 'r') as zipref:\n",
        "  zipref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Walking through the data directories\n",
        "import os\n",
        "\n",
        "for dirpath, dirname, filename in os.walk('10_food_classes_10_percent'):\n",
        "  print(f\"There are {len(dirname)} directories and {len(filename)} files in {dirpath}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOY4P3kff4r6",
        "outputId": "97a278c0-f858-4b93-8df2-bae599a08e6e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 files in 10_food_classes_10_percent.\n",
            "There are 10 directories and 0 files in 10_food_classes_10_percent/train.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/chicken_curry.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/hamburger.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/pizza.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/sushi.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/ice_cream.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/ramen.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/fried_rice.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/chicken_wings.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/grilled_salmon.\n",
            "There are 0 directories and 75 files in 10_food_classes_10_percent/train/steak.\n",
            "There are 10 directories and 0 files in 10_food_classes_10_percent/test.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/chicken_curry.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/hamburger.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/pizza.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/sushi.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/ice_cream.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/ramen.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/fried_rice.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/chicken_wings.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/grilled_salmon.\n",
            "There are 0 directories and 250 files in 10_food_classes_10_percent/test/steak.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turning our data into dataset\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = (224,224)\n",
        "\n",
        "train_dir = '10_food_classes_10_percent/train/'\n",
        "test_dir = '10_food_classes_10_percent/test/'\n",
        "\n",
        "train_data = image_dataset_from_directory(directory = train_dir,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          image_size = IMAGE_SIZE,\n",
        "                                          labels = 'inferred',\n",
        "                                          label_mode = 'categorical',\n",
        "                                          shuffle = True,\n",
        "                                          seed = 42)\n",
        "\n",
        "test_data = image_dataset_from_directory(directory = test_dir,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          image_size = IMAGE_SIZE,\n",
        "                                          labels = 'inferred',\n",
        "                                          label_mode = 'categorical',\n",
        "                                          shuffle = False,\n",
        "                                          seed = 42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnm2jWePgtRT",
        "outputId": "b7581c4e-c459-447b-9b68-48493a549cd4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the class names\n",
        "class_names = train_data.class_names\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nbibJR9heRw",
        "outputId": "dcd988bb-1fdb-44bd-93b9-68911c482427"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting up Callbacks"
      ],
      "metadata": {
        "id": "bbgT1PX8qttc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Callbacks** are helpful extra functionalities that can be added to models during or after the fitting process.\n",
        "\n",
        "Previously, we got familiar with the LearningRateScheduler callback, that helped us find the ideal learning rate for our model.\n",
        "\n",
        "In the future, we will be using more of them in order to make our work easier and more efficient. Some of the callbacks we'll be using are:\n",
        "\n",
        "\n",
        "1.   **TensorBoard** - logs the performance of multiple models, and helps compare said models visually in a single, easy to use interface. Can be accessed with `tf.keras.callbacks.TensorBoard()`.\n",
        "2.   **Model Checkpointing** - saves our model as it trains, even before it finishes training fully, so we can resume training at a later time. Helpful when training a model takes a long time. Can be accessed with `tf.keras.callbacks.ModelCheckpoint()`.\n",
        "3.   **Early Stopping** - Stops training the model when it fails to improve. Helpful when the number of epochs can't be decided, or when we have a large dataset and don't know how long the training will take. Can be accessed with `tf.keras.callbacks.EarlyStopping()`.\n",
        "\n"
      ],
      "metadata": {
        "id": "mtCzFblAqxTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mainly, we will be using the TensorBoard callback, to easily compare the results of different models.\n",
        "\n",
        "For this, we will write a function that will create a TensorBoard callback for each model we train, and saves all these callbacks to one folder."
      ],
      "metadata": {
        "id": "F4bkmt_JuOhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "def create_tb_callback(dir_name, experiment_name):\n",
        "  '''\n",
        "  Creates a TensorBoard callback for a model and saves it to the dir_name/experiment_name/CURRENT_DATATIME\n",
        "  directory.\n",
        "  '''\n",
        "  log_dir = dir_name + '/' + experiment_name + '/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "  tb_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
        "  print(f'Creating a TensorBoard log in {log_dir}')\n",
        "  return tb_callback"
      ],
      "metadata": {
        "id": "P6wwEm15hsP_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using Transfer Learning & Creating a Feature Extractor"
      ],
      "metadata": {
        "id": "cSUvo1NvxRd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now comes the exciting part of using a pretrained model for our image classification problem.\n",
        "\n",
        "For TensorFlow, there exists a huge number of different models trained for various applications, that are ready to be applied and fine-tuned for our custom problems, and all of them could be found on [TensorFlow Hub](https://www.kaggle.com/models?tfhub-redirect=true).\n",
        "\n",
        "For our problem, we will be using two of the most popular and well-performing architectures:\n",
        "\n",
        "1.   [ResNetV2](https://arxiv.org/abs/1603.05027) -  a state of the art computer vision model architecture from 2016. Can be found [here](https://www.kaggle.com/models/google/resnet-v2) on TensorFlow Hub.\n",
        "2.   [EfficientNetV2](https://arxiv.org/abs/1905.11946) - a state of the art computer vision architecture from 2019. Can be found [here](https://www.kaggle.com/models/google/efficientnet-v2) on TensorFlow Hub.\n",
        "\n",
        "How do we know which model performs the best for a certain type of application? Luckily, there is a great website called [paperwithcode.com/sota](https://paperswithcode.com/sota), that contain many benchmarks for various models and applications.\n",
        "\n",
        "Important to remember is that the best performing model is not always the best choice for every problem, things like model's size and complexity and the size of the dataset, among others, need to be taken into consideration when choosing a model.\n",
        "\n",
        "For example, choosing an overly complex and huge model for a relatively small dataset will most likely yield bad results. Another example is that we may want a model that trains and predicts fast, in this case, a small, not the best performing model would be ideal."
      ],
      "metadata": {
        "id": "aRQZY70-xdJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need to download the models (feature extractors) from the hub.\n",
        "\n",
        "Luckily, the hub gives us the needed code to instantly download any model we need, and gives us the path to access the model.\n",
        "\n",
        "We will write a function that will take in the URL of the model, and create a keras feature extractor our of it."
      ],
      "metadata": {
        "id": "2G_zEXm35P_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving models' urls in variables\n",
        "effnetb0_url = \"https://www.kaggle.com/models/google/efficientnet-v2/TensorFlow2/imagenet1k-b0-feature-vector/2\"\n",
        "resnetv2_url = \"https://www.kaggle.com/models/google/resnet-v2/TensorFlow2/50-feature-vector/2\""
      ],
      "metadata": {
        "id": "OIDxiXHG8EAj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "def create_model(model_url, num_classes = 10):\n",
        "  '''\n",
        "  Creates a Keras sequential feature extractor by providing a model_url, and the\n",
        "  number of classes of the output layer.\n",
        "\n",
        "  Args:\n",
        "    model_url: the URL of the feature extractor.\n",
        "    num_classes: number of classes in the output classifier layer. Default = 10.\n",
        "\n",
        "  Returns:\n",
        "    An uncompiled Keras sequential feature extractor.\n",
        "  '''\n",
        "  # Downloading the pre-trained model and saving it as a keras layer\n",
        "  feature_extraction_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable = False, # We don't need to retrain the weights in the model, hence we freeze them by setting trainable to False\n",
        "                                           name = 'feature_extraction_layer',\n",
        "                                           input_shape = IMAGE_SIZE + (3,)) # Adding the color channel dimension in the input shape\n",
        "\n",
        "  # Creating the model with the feature extractor as the backbone\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Rescaling(1./255),\n",
        "      feature_extraction_layer,\n",
        "      tf.keras.layers.Dense(num_classes, activation = 'softmax', name = 'output_layer')\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "uBkzZWjK52hL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally, one model has a lot of variations, which are reflected by the number that comes after a model's name.\n",
        "\n",
        "For example, in our case, we are working with ResNetV2_50, but there are also ResNetV2_101, ResNetV2_152, etc. The number here represents the number of layers in the ResNet architecture, the higher the number, the more layers there are and the more complex and big the model is.\n",
        "\n",
        "For EfficientNetV2, there are also different variations. We are working with EfficientNetV2 that was trained on [ImageNet](https://www.image-net.org/)1k (1k means it was trained of 1000 classes of images, there is also 21k) with a size of B0, but there are also B1, B2, B3, etc. that contain more layers.\n",
        "\n",
        "All of these variations can be accessed through the TensorFlow Hub."
      ],
      "metadata": {
        "id": "J2PgGdyf_Pnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a ResNetV2 model using the function created aboce\n",
        "resnet_model = create_model(resnetv2_url,\n",
        "                            num_classes = len(class_names))"
      ],
      "metadata": {
        "id": "0m_5TZB66fgP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting a summary of the model\n",
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHRCLO4G9b_u",
        "outputId": "767f1760-339f-4e29-d956-a98cc175c565"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_1 (Rescaling)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " feature_extraction_layer (  (None, 2048)              23564800  \n",
            " KerasLayer)                                                     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23585290 (89.97 MB)\n",
            "Trainable params: 20490 (80.04 KB)\n",
            "Non-trainable params: 23564800 (89.89 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "resnet_model.compile(loss = 'categorical_crossentropy',\n",
        "                     optimizer = tf.keras.optimizers.Adam(),\n",
        "                     metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "wv1g6NSw9gOC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model and attaching a TensorBoard callback to it\n",
        "resnet_hitsory = resnet_model.fit(train_data,\n",
        "                                  epochs = 5,\n",
        "                                  steps_per_epoch = len(train_data),\n",
        "                                  validation_data = test_data,\n",
        "                                  validation_steps = len(test_data),\n",
        "                                  callbacks = [create_tb_callback(dir_name = 'tf_hub',\n",
        "                                                                  experiment_name = 'resnet50V2')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6Pj4S1J9vQP",
        "outputId": "88b6a8f2-d418-45c9-ce24-28bca3f00278"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a TensorBoard log in tf_hub/resnet50V2/20240628-181223\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 14s 404ms/step - loss: 1.9677 - accuracy: 0.3480 - val_loss: 1.1992 - val_accuracy: 0.6212\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 10s 398ms/step - loss: 0.8807 - accuracy: 0.7373 - val_loss: 0.8600 - val_accuracy: 0.7212\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 10s 404ms/step - loss: 0.6127 - accuracy: 0.8147 - val_loss: 0.7729 - val_accuracy: 0.7480\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 10s 399ms/step - loss: 0.4749 - accuracy: 0.8760 - val_loss: 0.7050 - val_accuracy: 0.7724\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 13s 533ms/step - loss: 0.3714 - accuracy: 0.9133 - val_loss: 0.6751 - val_accuracy: 0.7816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Already we can see a huge improvement over any model we've built previously! We managed to get a 78.16% validation accuracy as opposed to the ~30% accuracy we got from TinyVGG. All that while training on only 10% of the data, and for way less time (since we're only training the output layer)."
      ],
      "metadata": {
        "id": "pHLISUgLEnU5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xby2EIsBD_qi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}